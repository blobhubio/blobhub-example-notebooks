{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Tutorial - Super Resolution Vision Model - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tutorial demonstrates loading trained model weights from BlobHub and using for inference. \n",
    "\n",
    "The model used in this tutorial is trained to scale up images (increase image resolution).\n",
    "\n",
    "References: \n",
    "- BlobHub model  \n",
    "  https://blobhub.io/onnx-vision-models/super-resolution\n",
    "- Original tutorial  \n",
    "  https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Install Dependencies](#Install-Dependencies)\n",
    "- [Download Model from BlobHub](#Download-Model-from-BlobHub)\n",
    "- [Run Model Inference](#Run-Model-Inference)\n",
    "- [Compare Results](#Compare-Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following packages are required for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install blobhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model from BlobHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet downloads model from public BlobHub blob. Blob reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG_ID = \"onnx-vision-models\"\n",
    "BLOB_ID = \"super-resolution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model downloading code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blobhub.blob import Blob, Revision\n",
    "from blobhub.presets.onnx import Onnx, Model       \n",
    "\n",
    "# Find blob\n",
    "blob = Blob(org_id=ORG_ID, blob_id=BLOB_ID)\n",
    "revision = blob.revisions.latest()\n",
    "\n",
    "# Initialize preset\n",
    "onnx = Onnx(revision=revision)\n",
    "\n",
    "# Download and save the model\n",
    "downloaded_model = onnx.download()\n",
    "assert None != downloaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded model is stored locally and is accessible under:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_model.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check model correctness (ONNX model consistency check):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(downloaded_model.path)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize ONNX runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(downloaded_model.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load input image and convert to tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the image \n",
    "input_image_url = \"https://static.blobhub.io/revisions/01cba831-d693-4adf-b0c8-ded7e553c019/bridge_224x224.jpg\"\n",
    "response = requests.get(input_image_url)\n",
    "input_image_original = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Resize image to match model input dimensions\n",
    "resize = transforms.Resize([224, 224])\n",
    "input_image = resize(input_image_original)\n",
    "\n",
    "# Convert image into YCbCr color space \n",
    "img_ycbcr = input_image.convert(\"YCbCr\")\n",
    "img_in_y, img_in_cb, img_in_cr = img_ycbcr.split()\n",
    "\n",
    "# Create tensor based on luma signal\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_in_y = to_tensor(img_in_y)\n",
    "img_in_y.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_in_y)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "img_out_y_out = ort_outs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct image object based on the model output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert model output into an image (just Y channel)\n",
    "img_out_y = Image.fromarray(np.uint8((img_out_y_out[0] * 255.0).clip(0, 255)[0]), mode='L')\n",
    "\n",
    "# Reconstruct the image by using model-resized luma channel and maually-resized chroma components\n",
    "output_image = Image.merge(\n",
    "    \"YCbCr\", [\n",
    "        img_out_y,\n",
    "        img_in_cb.resize(img_out_y.size, Image.BICUBIC),\n",
    "        img_in_cr.resize(img_out_y.size, Image.BICUBIC),\n",
    "    ]).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resized image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
