{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Tutorial - Single Shot MultiBox Detector Model - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tutorial demonstrates loading trained model weights from BlobHub and using for inference. \n",
    "\n",
    "The model used in this tutorial is trained to scale up images (increase image resolution).\n",
    "\n",
    "References: \n",
    "- BlobHub model  \n",
    "  https://blobhub.io/onnx-vision-models/object-detection\n",
    "- Original tutorial  \n",
    "  https://github.com/onnx/tutorials/blob/master/tutorials/OnnxRuntimeServerSSDModel.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Install Dependencies](#Install-Dependencies)\n",
    "- [Download Model from BlobHub](#Download-Model-from-BlobHub)\n",
    "- [Run Model Inference](#Run-Model-Inference)\n",
    "- [Compare Results](#Compare-Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following packages are required for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install blobhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model from BlobHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet downloads model from public BlobHub blob. Blob reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG_ID = \"onnx-vision-models\"\n",
    "BLOB_ID = \"object-detection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model downloading code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blobhub.blob import Blob, Revision\n",
    "from blobhub.presets.onnx import Onnx, Model       \n",
    "\n",
    "# Find blob\n",
    "blob = Blob(org_id=ORG_ID, blob_id=BLOB_ID)\n",
    "revision = blob.revisions.latest()\n",
    "\n",
    "# Initialize preset\n",
    "onnx = Onnx(revision=revision)\n",
    "\n",
    "# Download and save the model\n",
    "downloaded_model = onnx.download()\n",
    "assert None != downloaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded model is stored locally and is accessible under:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_model.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the list of class labels the model is trained to recognize. Labels are stored seoarately from model ONNX blob. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_url = \"https://static.blobhub.io/revisions/5c669267-3dc3-4179-81c3-a5a2aad24dad/coco_classes.txt\"\n",
    "classes_response = requests.get(classes_url)\n",
    "classes = classes_response.text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check model correctness (ONNX model consistency check):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(downloaded_model.path)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize ONNX runtime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(downloaded_model.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load input image and convert to tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image \n",
    "# input_image_url = \"https://static.blobhub.io/revisions/5c669267-3dc3-4179-81c3-a5a2aad24dad/interior.jpg\"\n",
    "input_image_url = \"https://static.blobhub.io/revisions/5c669267-3dc3-4179-81c3-a5a2aad24dad/highway.jpg\"\n",
    "response = requests.get(input_image_url)\n",
    "input_image_original = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Model parameters (can be inferred from the model topology)\n",
    "resized_width = 1200  \n",
    "resized_height = 1200\n",
    "\n",
    "# Resize image to match model input dimensions\n",
    "input_image = input_image_original.resize((resized_width, resized_height), Image.BILINEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image to model input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_data = np.array(input_image)\n",
    "image_data = np.transpose(image_data, [2, 0, 1])\n",
    "image_data = np.expand_dims(image_data, 0)\n",
    "mean_vec = np.array([0.485, 0.456, 0.406])\n",
    "stddev_vec = np.array([0.229, 0.224, 0.225])\n",
    "norm_image_data = np.zeros(image_data.shape).astype('float32')\n",
    "for i in range(image_data.shape[1]):\n",
    "    norm_image_data[:,i,:,:] = (image_data[:,i,:,:]/255 - mean_vec[i]) / stddev_vec[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_inputs = {ort_session.get_inputs()[0].name: norm_img_data}\n",
    "ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract model outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = ort_outs[0].flatten()\n",
    "labels = ort_outs[1].flatten()\n",
    "scores = ort_outs[2].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display image with bounding boxes and appropriate class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Plot the bounding boxes on the image\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(1, figsize=(12,9))\n",
    "ax.imshow(input_image)\n",
    "\n",
    "# Walk over all bounding boxes found by the model\n",
    "for c in range(200):\n",
    "    # We pick a subset of labels based on confidence score \n",
    "    if scores[c] < 0.2:\n",
    "        continue\n",
    "    \n",
    "    base_index = c * 4\n",
    "    y1, x1, y2, x2 = bboxes[base_index] * resized_height, bboxes[base_index + 1] * resized_width, bboxes[base_index + 2] * resized_height, bboxes[base_index + 3] * resized_width \n",
    "    color = 'blue'\n",
    "    box_h = (y2 - y1)\n",
    "    box_w = (x2 - x1)\n",
    "    bbox = patches.Rectangle((y1, x1), box_h, box_w, linewidth=2, edgecolor=color, facecolor='none')\n",
    "    ax.add_patch(bbox)\n",
    "    label_text = \"{} ({:0.2f})\".format(classes[labels[c] - 1], scores[c])\n",
    "    plt.text(y1, x1, s=label_text, color='white', verticalalignment='top', bbox={'color': \"green\", 'pad': 0})\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
